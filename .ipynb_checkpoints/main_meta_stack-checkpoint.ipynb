{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pandas_market_calendars as mcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyse_holidays():\n",
    "    nyse = mcal.get_calendar('NYSE')\n",
    "    holidays = nyse.holidays()\n",
    "    nyse_holidays = holidays.holidays\n",
    "    \n",
    "    return nyse_holidays\n",
    "\n",
    "# shift dates if they fall on a weekend/trading holiday\n",
    "def get_prev_business_date(date, holidays):\n",
    "    if date.isoweekday() in set((6, 7)):\n",
    "        #if date falls on a weekend, move the date back\n",
    "        date -= pd.offsets.BDay(n = date.isoweekday() % 5)\n",
    "    elif date in holidays:\n",
    "        #if date is a NYSE trading holiday, move the date back\n",
    "        date -= pd.offsets.BDay(n=1)  # get prev day\n",
    "        # now if the new date is on a weekend, move it back \n",
    "        if date.isoweekday() in set((6, 7)):\n",
    "            date -= pd.offsets.BDay(n = date.isoweekday() % 5)\n",
    "\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Price Data\n",
    "wd = os.getcwd()\n",
    "\n",
    "df = pd.read_excel(wd+'/Data/'+'WTI.xlsx')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.strftime('%m-%d-%Y')\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Features\n",
    "\n",
    "xlsx_files = glob.glob(os.path.join(wd, 'Data', \"*.xlsx\"))\n",
    "holidays = nyse_holidays()\n",
    "daily_data = ['DowJones', 'SPX', 'USDEUR', 'DAX', 'NG1', 'Nikkei', 'HangSeng', 'GT10']\n",
    "\n",
    "for file in xlsx_files:\n",
    "    data_name = file.split(\"/\")[-1].split('.')[0]\n",
    "    data_name = data_name.replace(\" \", \"_\")\n",
    "    \n",
    "    if data_name == 'WTI':\n",
    "        continue\n",
    "        \n",
    "    df_temp = pd.read_excel(file)\n",
    "    df_temp['Date'] = pd.to_datetime(df_temp['Date'])\n",
    "    #print(data_name)\n",
    "    if data_name in daily_data:\n",
    "        df_temp['Date'] = df_temp['Date'].dt.strftime('%m-%d-%Y')\n",
    "        df_temp.set_index('Date', inplace=True)\n",
    "    else:\n",
    "        df_temp['Artificial Date'] = df_temp['Date'].apply(lambda x: get_prev_business_date(x, holidays))\n",
    "        df_temp['Artificial Date'] = df_temp['Artificial Date'].dt.strftime('%m-%d-%Y')\n",
    "        df_temp = df_temp.drop(columns=['Date'])\n",
    "        df_temp.set_index('Artificial Date', inplace=True)\n",
    "    \n",
    "    try:\n",
    "        df[df_temp.columns[0] + '_' + data_name] = df_temp[df_temp.columns[0]]\n",
    "    except ValueError:\n",
    "        print(data_name, \"Error\")\n",
    "\n",
    "#backfill data for other frequencies\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "idx = list(df.index).index('12-31-2020')\n",
    "df = df.iloc[idx:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Sign and returns Data point\n",
    "df['PX_Sign'] = np.sign(df['PX_LAST'] - df['PX_LAST'].shift(-1))\n",
    "df.loc[df.PX_Sign == 0, 'PX_Sign'] = int(1)\n",
    "df['Returns'] = df['PX_LAST']/df['PX_LAST'].shift(-1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>PX_VOLUME</th>\n",
       "      <th>PX_LAST_Cass_Freight_Rates</th>\n",
       "      <th>PX_LAST_OPEC_daily_prod</th>\n",
       "      <th>PX_LAST_Europe_Inflation</th>\n",
       "      <th>PX_LAST_US_Inflation</th>\n",
       "      <th>PX_LAST_SPX</th>\n",
       "      <th>PX_LAST_Germany_GDP</th>\n",
       "      <th>PX_LAST_Russia_Industrial_Production</th>\n",
       "      <th>PX_LAST_Russia_daily_prod</th>\n",
       "      <th>...</th>\n",
       "      <th>PX_LAST_Nikkei</th>\n",
       "      <th>PX_LAST_US_IndProd_Index</th>\n",
       "      <th>PX_LAST_Russia_GDP</th>\n",
       "      <th>PX_MID_GT10</th>\n",
       "      <th>PX_LAST_HangSeng</th>\n",
       "      <th>PX_LAST_China_GDP</th>\n",
       "      <th>PX_LAST_Europe_IndProd_exConstruction</th>\n",
       "      <th>PX_LAST_US_daily_prod</th>\n",
       "      <th>PX_Sign</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12-31-2020</th>\n",
       "      <td>48.52</td>\n",
       "      <td>181894.0</td>\n",
       "      <td>1.122</td>\n",
       "      <td>25480.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3756.07</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9654.725</td>\n",
       "      <td>...</td>\n",
       "      <td>27444.17</td>\n",
       "      <td>98.2854</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.916</td>\n",
       "      <td>27231.13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>101.8</td>\n",
       "      <td>11063.097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-30-2020</th>\n",
       "      <td>48.40</td>\n",
       "      <td>266957.0</td>\n",
       "      <td>1.154</td>\n",
       "      <td>25260.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3732.04</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9621.970</td>\n",
       "      <td>...</td>\n",
       "      <td>27444.17</td>\n",
       "      <td>97.1609</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.925</td>\n",
       "      <td>27147.11</td>\n",
       "      <td>4.9</td>\n",
       "      <td>101.8</td>\n",
       "      <td>11121.033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-29-2020</th>\n",
       "      <td>48.00</td>\n",
       "      <td>213778.0</td>\n",
       "      <td>1.154</td>\n",
       "      <td>25260.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3727.04</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9621.970</td>\n",
       "      <td>...</td>\n",
       "      <td>27568.15</td>\n",
       "      <td>97.1609</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.939</td>\n",
       "      <td>26568.49</td>\n",
       "      <td>4.9</td>\n",
       "      <td>101.8</td>\n",
       "      <td>11121.033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-28-2020</th>\n",
       "      <td>47.62</td>\n",
       "      <td>238462.0</td>\n",
       "      <td>1.154</td>\n",
       "      <td>25260.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3735.36</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9621.970</td>\n",
       "      <td>...</td>\n",
       "      <td>26854.03</td>\n",
       "      <td>97.1609</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.925</td>\n",
       "      <td>26314.63</td>\n",
       "      <td>4.9</td>\n",
       "      <td>101.8</td>\n",
       "      <td>11121.033</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.012648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-24-2020</th>\n",
       "      <td>48.23</td>\n",
       "      <td>167390.0</td>\n",
       "      <td>1.154</td>\n",
       "      <td>25260.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3703.06</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9621.970</td>\n",
       "      <td>...</td>\n",
       "      <td>26668.35</td>\n",
       "      <td>97.1609</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.926</td>\n",
       "      <td>26386.56</td>\n",
       "      <td>4.9</td>\n",
       "      <td>101.8</td>\n",
       "      <td>11121.033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-08-1990</th>\n",
       "      <td>21.62</td>\n",
       "      <td>38007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38294.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.012</td>\n",
       "      <td>2816.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.063258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-05-1990</th>\n",
       "      <td>23.08</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38274.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.984</td>\n",
       "      <td>2839.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.014097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-04-1990</th>\n",
       "      <td>23.41</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38712.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.972</td>\n",
       "      <td>2867.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.011402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-03-1990</th>\n",
       "      <td>23.68</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.974</td>\n",
       "      <td>2858.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-02-1990</th>\n",
       "      <td>22.89</td>\n",
       "      <td>719.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.930</td>\n",
       "      <td>2838.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7796 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PX_LAST  PX_VOLUME  PX_LAST_Cass_Freight_Rates  \\\n",
       "Date                                                         \n",
       "12-31-2020    48.52   181894.0                       1.122   \n",
       "12-30-2020    48.40   266957.0                       1.154   \n",
       "12-29-2020    48.00   213778.0                       1.154   \n",
       "12-28-2020    47.62   238462.0                       1.154   \n",
       "12-24-2020    48.23   167390.0                       1.154   \n",
       "...             ...        ...                         ...   \n",
       "01-08-1990    21.62    38007.0                         NaN   \n",
       "01-05-1990    23.08       50.0                         NaN   \n",
       "01-04-1990    23.41     2500.0                         NaN   \n",
       "01-03-1990    23.68     1566.0                         NaN   \n",
       "01-02-1990    22.89      719.0                         NaN   \n",
       "\n",
       "            PX_LAST_OPEC_daily_prod  PX_LAST_Europe_Inflation  \\\n",
       "Date                                                            \n",
       "12-31-2020                  25480.0                      -0.3   \n",
       "12-30-2020                  25260.0                      -0.3   \n",
       "12-29-2020                  25260.0                      -0.3   \n",
       "12-28-2020                  25260.0                      -0.3   \n",
       "12-24-2020                  25260.0                      -0.3   \n",
       "...                             ...                       ...   \n",
       "01-08-1990                      NaN                       NaN   \n",
       "01-05-1990                      NaN                       NaN   \n",
       "01-04-1990                      NaN                       NaN   \n",
       "01-03-1990                      NaN                       NaN   \n",
       "01-02-1990                      NaN                       NaN   \n",
       "\n",
       "            PX_LAST_US_Inflation  PX_LAST_SPX  PX_LAST_Germany_GDP  \\\n",
       "Date                                                                 \n",
       "12-31-2020                   1.4      3756.07                 -3.3   \n",
       "12-30-2020                   1.2      3732.04                 -3.8   \n",
       "12-29-2020                   1.2      3727.04                 -3.8   \n",
       "12-28-2020                   1.2      3735.36                 -3.8   \n",
       "12-24-2020                   1.2      3703.06                 -3.8   \n",
       "...                          ...          ...                  ...   \n",
       "01-08-1990                   NaN       353.79                  NaN   \n",
       "01-05-1990                   NaN       352.20                  NaN   \n",
       "01-04-1990                   NaN       355.67                  NaN   \n",
       "01-03-1990                   NaN       358.76                  NaN   \n",
       "01-02-1990                   NaN       359.69                  NaN   \n",
       "\n",
       "            PX_LAST_Russia_Industrial_Production  PX_LAST_Russia_daily_prod  \\\n",
       "Date                                                                          \n",
       "12-31-2020                                   3.8                   9654.725   \n",
       "12-30-2020                                  -1.0                   9621.970   \n",
       "12-29-2020                                  -1.0                   9621.970   \n",
       "12-28-2020                                  -1.0                   9621.970   \n",
       "12-24-2020                                  -1.0                   9621.970   \n",
       "...                                          ...                        ...   \n",
       "01-08-1990                                   NaN                        NaN   \n",
       "01-05-1990                                   NaN                        NaN   \n",
       "01-04-1990                                   NaN                        NaN   \n",
       "01-03-1990                                   NaN                        NaN   \n",
       "01-02-1990                                   NaN                        NaN   \n",
       "\n",
       "            ...  PX_LAST_Nikkei  PX_LAST_US_IndProd_Index  PX_LAST_Russia_GDP  \\\n",
       "Date        ...                                                                 \n",
       "12-31-2020  ...        27444.17                   98.2854                -1.8   \n",
       "12-30-2020  ...        27444.17                   97.1609                -3.5   \n",
       "12-29-2020  ...        27568.15                   97.1609                -3.5   \n",
       "12-28-2020  ...        26854.03                   97.1609                -3.5   \n",
       "12-24-2020  ...        26668.35                   97.1609                -3.5   \n",
       "...         ...             ...                       ...                 ...   \n",
       "01-08-1990  ...        38294.96                       NaN                 NaN   \n",
       "01-05-1990  ...        38274.76                       NaN                 NaN   \n",
       "01-04-1990  ...        38712.88                       NaN                 NaN   \n",
       "01-03-1990  ...             NaN                       NaN                 NaN   \n",
       "01-02-1990  ...             NaN                       NaN                 NaN   \n",
       "\n",
       "            PX_MID_GT10  PX_LAST_HangSeng  PX_LAST_China_GDP  \\\n",
       "Date                                                           \n",
       "12-31-2020        0.916          27231.13                6.5   \n",
       "12-30-2020        0.925          27147.11                4.9   \n",
       "12-29-2020        0.939          26568.49                4.9   \n",
       "12-28-2020        0.925          26314.63                4.9   \n",
       "12-24-2020        0.926          26386.56                4.9   \n",
       "...                 ...               ...                ...   \n",
       "01-08-1990        8.012           2816.24                NaN   \n",
       "01-05-1990        7.984           2839.94                NaN   \n",
       "01-04-1990        7.972           2867.95                NaN   \n",
       "01-03-1990        7.974           2858.72                NaN   \n",
       "01-02-1990        7.930           2838.07                NaN   \n",
       "\n",
       "            PX_LAST_Europe_IndProd_exConstruction  PX_LAST_US_daily_prod  \\\n",
       "Date                                                                       \n",
       "12-31-2020                                  101.8              11063.097   \n",
       "12-30-2020                                  101.8              11121.033   \n",
       "12-29-2020                                  101.8              11121.033   \n",
       "12-28-2020                                  101.8              11121.033   \n",
       "12-24-2020                                  101.8              11121.033   \n",
       "...                                           ...                    ...   \n",
       "01-08-1990                                    NaN                    NaN   \n",
       "01-05-1990                                    NaN                    NaN   \n",
       "01-04-1990                                    NaN                    NaN   \n",
       "01-03-1990                                    NaN                    NaN   \n",
       "01-02-1990                                    NaN                    NaN   \n",
       "\n",
       "            PX_Sign   Returns  \n",
       "Date                           \n",
       "12-31-2020      1.0  0.002479  \n",
       "12-30-2020      1.0  0.008333  \n",
       "12-29-2020      1.0  0.007980  \n",
       "12-28-2020     -1.0 -0.012648  \n",
       "12-24-2020      1.0  0.002286  \n",
       "...             ...       ...  \n",
       "01-08-1990     -1.0 -0.063258  \n",
       "01-05-1990     -1.0 -0.014097  \n",
       "01-04-1990     -1.0 -0.011402  \n",
       "01-03-1990      1.0  0.034513  \n",
       "01-02-1990      NaN       NaN  \n",
       "\n",
       "[7796 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'WTI Price (1990-2021)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_t = df.copy()\n",
    "ax = df_t[df_t.columns[0]][::-1].plot()\n",
    "ax.set_ylabel(\"WTI Price\")\n",
    "ax.set_title('WTI Price (1990-2021)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = ['PX_LAST']\n",
    "classification = ['PX_Sign']\n",
    "returns = ['Returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict for frequency adjustment\n",
    "cols_freq = {\n",
    "    'PX_LAST':\"daily\",\n",
    "    'PX_VOLUME':\"daily\",\n",
    "    'PX_LAST_DowJones':\"daily\",\n",
    "    'PX_MID_GT10':\"daily\",\n",
    "    'PX_LAST_HangSeng':\"daily\",\n",
    "    'PX_LAST_Nikkei':\"daily\",\n",
    "    'PX_LAST_SPX':\"daily\",\n",
    "    'PX_LAST_USDEUR':\"daily\",\n",
    "    'PX_LAST_NG1':\"daily\",\n",
    "    'PX_LAST_DAX':\"daily\",\n",
    "    'PX_LAST_US_daily_prod':\"monthly\",\n",
    "    'PX_LAST_Cass_Freight_Rates':\"monthly\",\n",
    "    'PX_LAST_Canada_daily_prod':\"monthly\",\n",
    "    'PX_LAST_Russia_daily_prod':\"monthly\",\n",
    "    'PX_LAST_OPEC_daily_prod':\"monthly\",\n",
    "    'PX_LAST_US_Inflation':\"monthly\",\n",
    "    'PX_LAST_Europe_Inflation':\"monthly\",\n",
    "    'PX_LAST_Europe_IndProd_exConstruction':\"monthly\",\n",
    "    'PX_LAST_Russia_Industrial_Production':\"monthly\",\n",
    "    'PX_LAST_US_IndProd_Index':\"monthly\",\n",
    "    'PX_LAST_China_GDP':\"quarterly\",\n",
    "    'PX_LAST_Germany_GDP':\"quarterly\",\n",
    "    'PX_LAST_Japan_GDP':\"quarterly\",\n",
    "    'PX_LAST_Russia_GDP':\"quarterly\",\n",
    "    'PX_LAST_US_GDP':\"quarterly\",\n",
    "    'PX_Sign':'daily',\n",
    "    'Returns':'daily'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_lag(df, column, lag):\n",
    "    lag = lag+1\n",
    "    if column==0:\n",
    "        for i in range(1, lag):\n",
    "            #creating new column here since column==0 is target\n",
    "            \n",
    "            df[df.columns[column] + '_t-' + str(i)] = df[df.columns[column]].shift(-i)\n",
    "            cols_freq[df.columns[column]+'_t-'+str(i)] = \"daily\"\n",
    "    else:\n",
    "        for i in range(1, lag):\n",
    "            #replacing old column here and renaming\n",
    "            df[df.columns[column]] = df[df.columns[column]].shift(-i)\n",
    "            df.rename(columns={df.columns[column]:df.columns[column]+'_t-'+str(i)}, inplace=True)\n",
    "            new_col = df.columns[column]\n",
    "            cols_freq[new_col] = \"daily\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def ma(df, column, freq = \"monthly\"):\n",
    "    if freq == \"monthly\":\n",
    "        #creating temp column to get values\n",
    "        df[df.columns[column] + '_temp'] = df[df.columns[column]]\n",
    "        \n",
    "        for i in range(0, len(df[df.columns[column]])-22):\n",
    "            df.iloc[i, column] = np.mean(df.iloc[i:i+22, -1])\n",
    "        \n",
    "        #dropping temp column\n",
    "        drop_col_name = df.columns[column] + '_temp'\n",
    "        df = df.loc[:, ~df.columns.isin([drop_col_name])]\n",
    "        \n",
    "        #renaming column to indicate moving average\n",
    "        df.rename(columns={df.columns[column]:df.columns[column]+'_SMA22'}, inplace=True)\n",
    "        cols_freq[df.columns[column]] = \"monthly\"\n",
    "    elif freq == \"quarterly\":\n",
    "        #creating temp column to get values\n",
    "        df[df.columns[column] + '_temp'] = df[df.columns[column]]\n",
    "        \n",
    "        for i in range(0, len(df[df.columns[column]])-65):\n",
    "            df.iloc[i, column] = np.mean(df.iloc[i:i+65, -1])\n",
    "        \n",
    "        #dropping temp column\n",
    "        drop_col_name = df.columns[column] + '_temp'\n",
    "        df = df.loc[:, ~df.columns.isin([drop_col_name])]\n",
    "        \n",
    "        #renaming column to indicate moving average\n",
    "        df.rename(columns={df.columns[column]:df.columns[column]+'_SMA65'}, inplace=True)\n",
    "        cols_freq[df.columns[column]] = \"quarterly\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def lag_data(df, column, freq = \"monthly\"):\n",
    "    if freq == \"monthly\":\n",
    "        #replacing old column and renaming\n",
    "        df[df.columns[column]] = df[df.columns[column]].shift(-22)\n",
    "        df.rename(columns={df.columns[column]:df.columns[column]+'_M'}, inplace=True)\n",
    "    elif freq == \"quarterly\":\n",
    "        #replacing old column and renaming\n",
    "        df[df.columns[column]] = df[df.columns[column]].shift(-65)\n",
    "        df.rename(columns={df.columns[column]:df.columns[column]+'_Q'}, inplace=True)\n",
    "    elif freq == \"weekly\":\n",
    "        #replacing old column and renaming\n",
    "        df[df.columns[column]] = df[df.columns[column]].shift(-10)\n",
    "        df.rename(columns={df.columns[column]:df.columns[column]+'_W'}, inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"Frequency invalid\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_lag_ma_data(df, daily_lags = 1, cols_freq=cols_freq):\n",
    "    for i in range(len(df.columns)):\n",
    "        column_name = df.columns[i]\n",
    "        #print(column_name)\n",
    "        if cols_freq[column_name] == 'daily':\n",
    "            df = daily_lag(df, i, daily_lags)\n",
    "        else:\n",
    "            df = lag_data(df, i, cols_freq[column_name])\n",
    "            df = ma(df, i, cols_freq[column_name])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_day_change(df, column):\n",
    "    #creating new column here, will drop old column later in get_diffs\n",
    "    df[df.columns[column] + '_1D_change'] = df[df.columns[column]] - df[df.columns[column]].shift(-1)\n",
    "    return df\n",
    "\n",
    "def two_week_change(df, column):\n",
    "    #creating new column here, will drop old column later in get_diffs\n",
    "    df[df.columns[column] + '_2W_change'] = df[df.columns[column]] - df[df.columns[column]].shift(-10)\n",
    "    return df\n",
    "\n",
    "def one_month_change(df, column):\n",
    "    #creating new column here, will drop old column later in get_diffs\n",
    "    df[df.columns[column] + '_1M_change'] = df[df.columns[column]] - df[df.columns[column]].shift(-22)\n",
    "    return df\n",
    "\n",
    "def get_diffs(df, target, cols_freq=cols_freq, drop=True):\n",
    "    cols = []\n",
    "    for i in range(1, len(df.columns)):\n",
    "        column_name = df.columns[i]\n",
    "        #collecting old columns to drop later\n",
    "        cols.append(column_name)\n",
    "        \n",
    "        if cols_freq[column_name] == 'daily':\n",
    "            df = one_day_change(df, i)\n",
    "            df = two_week_change(df, i)\n",
    "            df = one_month_change(df, i)\n",
    "        elif cols_freq[column_name] == 'monthly':\n",
    "            df = two_week_change(df, i)\n",
    "            df = one_month_change(df, i)\n",
    "        elif cols_freq[column_name] == 'quarterly':\n",
    "            df = one_month_change(df, i)\n",
    "        \n",
    "    #dropping old columns\n",
    "    target_lagged = df.columns[0] + '_t-1'\n",
    "    cols.remove(target_lagged)\n",
    "    #print(cols)\n",
    "    df = df.loc[:, ~df.columns.isin(cols)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regime(df, end, start=0):\n",
    "    if start==0 and end==0:\n",
    "        return df\n",
    "    \n",
    "    if start!=0:\n",
    "        st_idx = list(df.index).index(start)\n",
    "    else:\n",
    "        st_idx = 0\n",
    "    end_idx = list(df.index).index(end)\n",
    "    df_reg = df.iloc[st_idx:end_idx,:]\n",
    "    return df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_data(df, features, regime, target=classification):\n",
    "    if target != prices:\n",
    "        features = ['PX_LAST'] + features\n",
    "    \n",
    "    df_trial = get_lag_ma_data(df[target + features])\n",
    "    df_trial = get_diffs(df_trial, target)\n",
    "    \n",
    "    df_trial = df_trial.dropna()\n",
    "    df_trial = df_trial[::-1]\n",
    "    \n",
    "    df_reg = make_regime(df_trial, end=regime[1], start=regime[0])\n",
    "    \n",
    "    df_target = df_reg[target]\n",
    "    df_features = df_reg.iloc[:, 1:]\n",
    "    \n",
    "    return df_target, df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def get_data_splits(target, features):\n",
    "    train_n = int(len(target) * 0.8)\n",
    "    train_x = features[:train_n].to_numpy()\n",
    "    train_y = target[:train_n].to_numpy()\n",
    "    test_x = features[train_n:].to_numpy()\n",
    "    test_y = target[train_n:].to_numpy()\n",
    "\n",
    "    splits = TimeSeriesSplit(n_splits=100)\n",
    "\n",
    "    split_train_x = []\n",
    "    split_val_x = []\n",
    "    split_train_y = []\n",
    "    split_val_y = []\n",
    "\n",
    "    for train_index, val_index in splits.split(train_x):\n",
    "        split_train_x.append(train_x[train_index])\n",
    "        split_train_y.append(train_y[train_index])\n",
    "        split_val_x.append(train_x[val_index])\n",
    "        split_val_y.append(train_y[val_index])\n",
    "        \n",
    "    split_data = [split_train_x, split_train_y, split_val_x, split_val_y]\n",
    "    train_data = [train_x, train_y]\n",
    "    test_data = [test_x, test_y]\n",
    "    \n",
    "    return split_data, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(split_data):\n",
    "    split_train_x = split_data[0]\n",
    "    split_train_y = split_data[1]\n",
    "    split_val_x = split_data[2]\n",
    "    split_val_y = split_data[3]\n",
    "    \n",
    "    alphas = np.arange(0.05, 1.01, 0.05)\n",
    "    alpha_mse = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        transformer = RobustScaler\n",
    "        model = linear_model.Lasso(alpha=alpha)\n",
    "        mse = []\n",
    "        for i in range(len(split_train_x)):\n",
    "            wrapped_model = TransformedTargetRegressor(regressor=model, transformer=RobustScaler())\n",
    "            wrapped_model.fit(split_train_x[i], split_train_y[i])\n",
    "            yhat = wrapped_model.predict(split_val_x[i])\n",
    "            mse.append(np.mean((yhat-split_val_y[i])**2))\n",
    "        alpha_mse.append(np.mean(mse))\n",
    "    a_star = alphas[np.argmin(alpha_mse)]\n",
    "    print('Alpha* = {}'.format(alphas[np.argmin(alpha_mse)]))\n",
    "    return alpha_mse, a_star\n",
    "\n",
    "def lasso_test(train_data, test_data, alpha):\n",
    "    train_x = train_data[0]\n",
    "    train_y = train_data[1]\n",
    "    test_x = test_data[0]\n",
    "    test_y = test_data[1]\n",
    "    \n",
    "    model = linear_model.Lasso(alpha=alpha)\n",
    "    wrapped_model = TransformedTargetRegressor(regressor=model, transformer=RobustScaler())\n",
    "    wrapped_model.fit(train_x, train_y)\n",
    "    pred = wrapped_model.predict(test_x)\n",
    "    mse = np.mean((pred-test_y)**2)\n",
    "    \n",
    "    return pred, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber(split_data):\n",
    "    split_train_x = split_data[0]\n",
    "    split_train_y = split_data[1]\n",
    "    split_val_x = split_data[2]\n",
    "    split_val_y = split_data[3]\n",
    "    \n",
    "    alphas = np.arange(0.05, 1.01, 0.05)\n",
    "    alpha_mse = []\n",
    "    \n",
    "    for alpha in alphas:                     \n",
    "        transformer = RobustScaler\n",
    "        model = linear_model.HuberRegressor(alpha=alpha)\n",
    "        mse = []\n",
    "        for i in range(len(split_train_x)):\n",
    "            wrapped_model = TransformedTargetRegressor(regressor=model, transformer=RobustScaler())\n",
    "            wrapped_model.fit(split_train_x[i], split_train_y[i])\n",
    "            yhat = wrapped_model.predict(split_val_x[i])\n",
    "            mse.append(np.mean((yhat-split_val_y[i])**2))\n",
    "        alpha_mse.append(np.mean(mse))\n",
    "    a_star = alphas[np.argmin(alpha_mse)]\n",
    "    print('Alpha* = {}'.format(a_star))\n",
    "    return alpha_mse, a_star\n",
    "\n",
    "def huber_test(train_data, test_data, alpha):\n",
    "    train_x = train_data[0]\n",
    "    train_y = train_data[1]\n",
    "    test_x = test_data[0]\n",
    "    test_y = test_data[1]\n",
    "    \n",
    "    model = linear_model.HuberRegressor(alpha=alpha)\n",
    "    wrapped_model = TransformedTargetRegressor(regressor=model, transformer=RobustScaler())\n",
    "    wrapped_model.fit(train_x, train_y)\n",
    "    pred = wrapped_model.predict(test_x)\n",
    "    mse = np.mean((pred-test_y)**2)\n",
    "    \n",
    "    return pred, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RF_regressor(split_data):\n",
    "    split_train_x = split_data[0]\n",
    "    split_train_y = split_data[1]\n",
    "    split_val_x = split_data[2]\n",
    "    split_val_y = split_data[3]\n",
    "    \n",
    "    estimators = np.arange(950, 1000, 10)\n",
    "    estimator_mse = []\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        model = RandomForestRegressor(n_estimators=estimator)\n",
    "        mse = []\n",
    "        model.fit(split_train_x[-1], split_train_y[-1])\n",
    "        yhat = model.predict(split_val_x[-1])\n",
    "        mse.append(np.mean((yhat-split_val_y[-1])**2))\n",
    "        estimator_mse.append(np.mean(mse))\n",
    "    best_est = estimators[np.argmin(estimator_mse)]\n",
    "    print('Efficient Estimator = {}'.format(best_est))\n",
    "    return estimator_mse, best_est\n",
    "\n",
    "def RF_regressor_test(train_data, test_data, best_est):\n",
    "    train_x = train_data[0]\n",
    "    train_y = train_data[1]\n",
    "    test_x = test_data[0]\n",
    "    test_y = test_data[1]\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=best_est)\n",
    "    model.fit(train_x, train_y)\n",
    "    pred = model.predict(test_x)\n",
    "    mse = np.mean((pred-test_y)**2)\n",
    "    \n",
    "    return pred, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def XGBoost(split_data):\n",
    "    split_train_x = split_data[0]\n",
    "    split_train_y = split_data[1]\n",
    "    split_val_x = split_data[2]\n",
    "    split_val_y = split_data[3]\n",
    "    \n",
    "    estimators = np.arange(10, 1000, 10)\n",
    "    estimator_mse = []\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        transformer = RobustScaler\n",
    "        model = xgb.XGBRegressor(n_estimators=estimator, subsample=1.0)\n",
    "        mse = []\n",
    "        \n",
    "        for i in range(len(split_train_x)):\n",
    "            wrapped_model = TransformedTargetRegressor(regressor=model, transformer=RobustScaler())\n",
    "            wrapped_model.fit(split_train_x[i], split_train_y[i])\n",
    "            yhat = wrapped_model.predict(split_val_x[i])\n",
    "            mse.append(np.mean((yhat-split_val_y[i])**2))\n",
    "        estimator_mse.append(np.mean(mse))\n",
    "    best_est = estimators[np.argmin(estimator_mse)]\n",
    "    print('Efficient Estimator = {}'.format(best_est))\n",
    "    return estimator_mse, best_est\n",
    "\n",
    "def XGBoost_test(train_data, test_data, best_est):\n",
    "    train_x = train_data[0]\n",
    "    train_y = train_data[1]\n",
    "    test_x = test_data[0]\n",
    "    test_y = test_data[1]\n",
    "    \n",
    "    model = xgb.XGBRegressor(n_estimators=best_est, subsample=1.0)\n",
    "    model.fit(train_x, train_y)\n",
    "    pred = wrapped_model.predict(test_x)\n",
    "    mse = np.mean((pred-test_y)**2)\n",
    "    \n",
    "    return pred, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Categories by Type\n",
    "fin_indices = ['PX_LAST_DAX', 'PX_LAST_DowJones', 'PX_MID_GT10',\n",
    "           'PX_LAST_HangSeng', 'PX_LAST_Nikkei', 'PX_LAST_SPX',\n",
    "           'PX_LAST_USDEUR']\n",
    "nat_gas = ['PX_LAST_NG1']\n",
    "gdp = ['PX_LAST_China_GDP', 'PX_LAST_Germany_GDP', 'PX_LAST_Japan_GDP',\n",
    "       'PX_LAST_Russia_GDP', 'PX_LAST_US_GDP']\n",
    "oil_prod = ['PX_LAST_Canada_daily_prod', 'PX_LAST_Russia_daily_prod',\n",
    "            'PX_LAST_OPEC_daily_prod', 'PX_LAST_US_daily_prod']\n",
    "freight = ['PX_LAST_Cass_Freight_Rates']\n",
    "inflation = ['PX_LAST_US_Inflation', 'PX_LAST_Europe_Inflation']\n",
    "ind_prod = ['PX_LAST_Europe_IndProd_exConstruction', \n",
    "            'PX_LAST_Russia_Industrial_Production',\n",
    "            'PX_LAST_US_IndProd_Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Categories by Date Range\n",
    "feat_1992 = ['PX_LAST_DAX', 'PX_LAST_DowJones', 'PX_MID_GT10', \n",
    "             'PX_LAST_HangSeng', 'PX_LAST_Nikkei', 'PX_LAST_SPX', \n",
    "             'PX_LAST_USDEUR', 'PX_LAST_NG1', 'PX_LAST_China_GDP', \n",
    "             'PX_LAST_Germany_GDP', 'PX_LAST_US_GDP', 'PX_LAST_US_daily_prod', \n",
    "             'PX_LAST_Cass_Freight_Rates', 'PX_LAST_US_Inflation', \n",
    "             'PX_LAST_Europe_IndProd_exConstruction', 'PX_LAST_US_IndProd_Index']\n",
    "feat_1996 = feat_1992 + ['PX_LAST_Japan_GDP', 'PX_LAST_Russia_GDP',\n",
    "                         'PX_LAST_Canada_daily_prod', 'PX_LAST_Russia_daily_prod']\n",
    "feat_2000 = feat_1996 + ['PX_LAST_OPEC_daily_prod', 'PX_LAST_Europe_Inflation']\n",
    "feat_2002 = feat_2000 + ['PX_LAST_Russia_Industrial_Production']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_92_99 = [0, '12-30-1999']\n",
    "reg_00_06 = ['04-03-2000', '12-29-2006']\n",
    "reg_07_12 = ['01-02-2007', '12-31-2012']\n",
    "reg_13_20 = ['01-02-2013', '12-31-2020']\n",
    "no_regime = [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_t.copy()\n",
    "features = feat_2002\n",
    "regime = no_regime\n",
    "\n",
    "meta_target, meta_features = get_final_data(df=df_m,\n",
    "                                           features=features,\n",
    "                                           regime=regime,\n",
    "                                           target=prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def meta_split(target, features):\n",
    "    split_1 = int(len(target) * 0.5)\n",
    "    split_2 = int(len(target) * 0.75)\n",
    "    \n",
    "    train_X = features[:split_1].to_numpy()\n",
    "    train_y = target[:split_1].to_numpy()\n",
    "    val_X = features[split_1:split_2].to_numpy()\n",
    "    val_y = target[split_1:split_2].to_numpy()\n",
    "    test_X = features[split_2:].to_numpy()\n",
    "    test_y = target[split_2:].to_numpy()\n",
    "    \n",
    "    train_data = [train_X, train_y, val_X, val_y]\n",
    "    test_data = [test_X, test_y]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train, meta_test = meta_split(meta_target, meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = []\n",
    "meta_prep_split, meta_prep_train, meta_prep_test = get_data_splits(meta_target, meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_lasso_mse, meta_lasso_alpha = lasso(meta_prep_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_huber_mse, meta_huber_alpha = huber(meta_prep_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rf_mse, meta_rf_best_est = RF_regressor(meta_prep_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_xgb_mse, meta_xgb_best_est = XGBoost(meta_prep_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.append(meta_lasso_alpha)\n",
    "hyper.append(meta_huber_alpha)\n",
    "hyper.append(meta_rf_best_est)\n",
    "hyper.append(meta_xgb_best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = meta_train[0]\n",
    "train_y = meta_train_data[1]\n",
    "val_x = train_data[2]\n",
    "val_y = train_data[3]\n",
    "    \n",
    "test_x = test_data[0]\n",
    "test_y = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_meta = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=meta_lasso_alpha)\n",
    "models_meta.append(TransformedTargetRegressor(regressor=lasso, transformer=RobustScaler()))\n",
    "models_meta[0].fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber = linear_model.HuberRegressor(alpha=meta_huber_alpha)\n",
    "models_meta.append(TransformedTargetRegressor(regressor=huber, transformer=RobustScaler()))\n",
    "models_meta[1].fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_meta.append(RandomForestRegressor(n_estimators=meta_rf_best_est))\n",
    "models_meta[2].fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(n_estimators=meta_xgb_best_est, subsample=1.0)\n",
    "models_meta.append(TransformedTargetRegressor(regressor=xgb_reg, transformer=RobustScaler()))\n",
    "models_meta[3].fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = []\n",
    "for i, x in enumerate(val_x):\n",
    "    err = []\n",
    "    for model in models_meta:\n",
    "        yhat = model.predict(x.reshape(1,-1))\n",
    "        err.append((yhat-val_y[i])**2)\n",
    "    model_num.append((np.argmin(err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_meta)):\n",
    "    print('Count of ', i, ' is ', model_num.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to choose best model for datapoint:\n",
    "    \n",
    "split = int(0.75*len(val_x))\n",
    "t_train_x = val_x[:split]\n",
    "t_train_y = model_label[:split]\n",
    "t_val_x = val_x[split:]\n",
    "t_val_y = model_label[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(2, 10, 1)\n",
    "scores = []\n",
    "for depth in depths:\n",
    "    dtree_model = DecisionTreeClassifier(max_depth = depth).fit(t_train_x, t_train_y)\n",
    "    dtree_score = dtree_model.score(t_val_X, t_val_y)\n",
    "    scores.append(dtree_score)\n",
    "    \n",
    "best_depth = depths[np.argmax(scores)]\n",
    "print('Best depth: ', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_final = DecisionTreeClassifier(max_depth=best_depth).fit(val_x, model_label)\n",
    "model_pred = dtree_final.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_preds = []\n",
    "for i, x in enumerate(test_x):\n",
    "    pred = models_meta[model_pred[i]].predict(x.reshape(1,-1))\n",
    "    meta_preds.append(pred)\n",
    "\n",
    "meta_mse = np.mean((meta_preds-test_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rmse = np.sqrt(meta_mse)\n",
    "print(\"Meta Learning RMSE = \", meta_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(meta_preds, label='pred')\n",
    "plt.plot(test_y, label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_t.copy()\n",
    "features = feat_2002\n",
    "regime = no_regime\n",
    "\n",
    "stack_target, stack_features = get_final_data(df=df_m,\n",
    "                                           features=features,\n",
    "                                           regime=regime,\n",
    "                                           target=prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_split, stack_train, stack_test = get_data_splits(stack_target, stack_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "st_train_x = stack_train[0]\n",
    "st_train_y = stack_train[1]\n",
    "st_test_x = stack_test[0]\n",
    "st_test_y = stack_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here using hyperparameters for full data that we got earlier above, if we need to run for each regime, will have to get those hyperparameters again for each. \n",
    "Don't run the immediately next block for now, but run the one after that to set stack_hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_lasso_mse, stack_lasso_alpha = lasso(stack_split)\n",
    "stack_huber_mse, stack_huber_alpha = huber(stack_split)\n",
    "stack_rf_mse, stack_rf_best_est = RF_regressor(stack_split)\n",
    "stack_xgb_mse, stack_xgb_best_est = XGBoost(stack_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_lasso_alpha = meta_lasso_alpha\n",
    "stack_huber_alpha = meta_huber_alpha\n",
    "stack_rf_best_est = meta_rf_best_est\n",
    "stack_xgb_best_est = meta_xgb_best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0 = list()\n",
    "level0.append(('xgb', TransformedTargetRegressor(regressor=xgb.XGBRegressor(n_estimators=stack_xgb_best_est, subsample=1.0)\n",
    "                                                 , transformer=RobustScaler())))\n",
    "level0.append(('rf', TransformedTargetRegressor(regressor=RandomForestRegressor(n_estimators=stack_rf_best_est), transformer=RobustScaler())))\n",
    "level0.append(('huber', TransformedTargetRegressor(regressor=linear_model.HuberRegressor(alpha=stack_huber_alpha), transformer=RobustScaler())))\n",
    "level0.append(('lasso', TransformedTargetRegressor(regressor=linear_model.Lasso(alpha=stack_lasso_alpha), transformer=RobustScaler())))\n",
    "level1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = StackingRegressor(estimators=level0, final_estimator=level1)\n",
    "stack_model.fit(st_train_x, st_train_y)\n",
    "stack_pred = stack_model.predict(st_test_x)\n",
    "stack_mse = np.mean((stack_pred - st_test_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_rmse = np.sqrt(stack_mse)\n",
    "print(\"Stacking RMSE = \", stack_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stack_pred, label='pred')\n",
    "plt.plot(st_test_y, label='true')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
